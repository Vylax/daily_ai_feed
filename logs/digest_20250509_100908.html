<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>AI Daily Digest - May 09, 2025</title>
<style>
        body { font-family: 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; line-height: 1.6; margin: 0; padding: 0; background-color: #f8f9fa; color: #24292e; } /* Updated base color */
        .container { width: 95%; max-width: 800px; margin: 20px auto; background-color: #ffffff; border: 1px solid #dfe2e5; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 8px rgba(0,0,0,0.05); } /* Adjusted border/shadow */
        .header { background-color: #0366d6; color: #ffffff; padding: 25px 30px; text-align: center; border-bottom: 5px solid #005cc5; } /* GitHub blue */
        .header h1 { margin: 0; font-size: 28px; font-weight: 600; }
        .header p { margin: 5px 0 0; font-size: 16px; font-style: italic; opacity: 0.9; }
        .overview { background-color: #f6f8fa; padding: 15px 25px; margin: 25px; border-left: 4px solid #0366d6; border-radius: 4px; } /* Lighter blue */
        .overview h3 { margin-top: 0; margin-bottom: 10px; color: #005cc5; font-size: 18px; }
        .overview ul { margin: 0; padding-left: 20px; }
        .overview li { margin-bottom: 5px; }
        .section { padding: 20px 30px; border-bottom: 1px solid #eaecef; } /* Lighter border */
        .section:last-child { border-bottom: none; }
        .section h2 { background-color: #f6f8fa; padding: 12px 20px; margin: -20px -30px 20px -30px; font-size: 20px; font-weight: 600; color: #24292e; border-bottom: 1px solid #eaecef; display: flex; align-items: center; } /* Lighter header */
        .section h2 img.google-icon { margin-right: 8px; }
        .item { margin-bottom: 25px; padding-bottom: 25px; border-bottom: 1px dashed #d1d5da; } /* Slightly darker dashed border */
        .item:last-child { margin-bottom: 0; padding-bottom: 0; border-bottom: none; }
        .item h3 { margin-top: 0; margin-bottom: 5px; font-size: 18px; color: #0366d6; font-weight: 600; } /* GitHub blue link color */
        .item p { margin-top: 5px; margin-bottom: 12px; font-size: 15px; color: #24292e; }
        .item p strong { color: #24292e; font-weight: 600; }
        .item a { color: #0366d6; text-decoration: none; }
        .item a:hover { text-decoration: underline; }
        .source-link { font-size: 0.9em; color: #586069; margin-top: -8px !important; margin-bottom: 15px !important; word-break: break-all; } /* GitHub secondary text color */
        .google-icon { width: 16px; height: 16px; vertical-align: middle; }
        .actionable-ideas-list ul { list-style-type: disc; padding-left: 20px; margin-top: 10px;}
        .actionable-ideas-list li { background-color: transparent; margin-bottom: 10px; padding: 0; border-left: none; border-radius: 0px; }
        .actionable-ideas-list li em { color: #586069; font-size: 0.9em; display: block; margin-top: 4px;}
        .market-pulse-list ul { list-style-type: disc; padding-left: 20px; }
        .market-pulse-list li { margin-bottom: 8px; }
        .market-pulse-list li .source-title { color: #586069; font-size: 0.9em; display: block; margin-top: 2px;} /* C.7 */
        .footer { text-align: center; padding: 20px; font-size: 12px; color: #586069; background-color: #f6f8fa; border-top: 1px solid #eaecef; }

        /* Styles for code blocks - aiming for VS Code Light+ look (GitHub inspired) */
        .codehilite { background: #f6f8fa; border: 1px solid #dfe2e5; padding: 12px 15px; border-radius: 6px; overflow-x: auto; font-family: Consolas, 'SFMono-Regular', 'Liberation Mono', Menlo, monospace; font-size: 14px; margin: 1em 0; line-height: 1.45; }
        .codehilite pre { margin: 0; padding: 0; background: transparent; border: none; font-family: inherit; font-size: inherit; white-space: pre; word-wrap: normal; } /* Ensure pre doesn't add extra styles */
        /* Pygments Classes - Based on GitHub Light theme */
        .codehilite .hll { background-color: #fffbdd; } /* Highlighted line */
        .codehilite .c { color: #6a737d; font-style: italic; } /* Comment */
        .codehilite .c1 { color: #6a737d; font-style: italic; } /* Comment.Single */
        .codehilite .cs { color: #6a737d; font-style: italic; } /* Comment.Special */
        .codehilite .k { color: #d73a49; } /* Keyword */
        .codehilite .kc { color: #d73a49; } /* Keyword.Constant */
        .codehilite .kd { color: #d73a49; } /* Keyword.Declaration */
        .codehilite .kn { color: #d73a49; } /* Keyword.Namespace */
        .codehilite .kp { color: #d73a49; } /* Keyword.Pseudo */
        .codehilite .kr { color: #d73a49; } /* Keyword.Reserved */
        .codehilite .kt { color: #d73a49; } /* Keyword.Type */
        .codehilite .m { color: #005cc5; } /* Literal.Number */
        .codehilite .mf { color: #005cc5; } /* Literal.Number.Float */
        .codehilite .mh { color: #005cc5; } /* Literal.Number.Hex */
        .codehilite .mi { color: #005cc5; } /* Literal.Number.Integer */
        .codehilite .mo { color: #005cc5; } /* Literal.Number.Oct */
        .codehilite .s { color: #032f62; } /* Literal.String */
        .codehilite .sa { color: #032f62; } /* Literal.String.Affix */
        .codehilite .sb { color: #032f62; } /* Literal.String.Backtick */
        .codehilite .sc { color: #032f62; } /* Literal.String.Char */
        .codehilite .dl { color: #032f62; } /* Literal.String.Delimiter */
        .codehilite .sd { color: #032f62; font-style: italic; } /* Literal.String.Doc */
        .codehilite .s2 { color: #032f62; } /* Literal.String.Double */
        .codehilite .se { color: #005cc5; } /* Literal.String.Escape */
        .codehilite .sh { color: #032f62; } /* Literal.String.Heredoc */
        .codehilite .si { color: #032f62; } /* Literal.String.Interpol */
        .codehilite .sx { color: #032f62; } /* Literal.String.Other */
        .codehilite .sr { color: #032f62; } /* Literal.String.Regex */
        .codehilite .s1 { color: #032f62; } /* Literal.String.Single */
        .codehilite .ss { color: #032f62; } /* Literal.String.Symbol */
        .codehilite .na { color: #005cc5; } /* Name.Attribute */
        .codehilite .nb { color: #005cc5; } /* Name.Builtin */
        .codehilite .nc { color: #6f42c1; } /* Name.Class */
        .codehilite .no { color: #005cc5; } /* Name.Constant */
        .codehilite .nd { color: #6f42c1; } /* Name.Decorator */
        .codehilite .ni { color: #005cc5; } /* Name.Entity */
        .codehilite .ne { color: #d73a49; font-weight: bold; } /* Name.Exception */
        .codehilite .nf { color: #6f42c1; } /* Name.Function */
        .codehilite .nl { color: #d73a49; } /* Name.Label */
        .codehilite .nn { color: #6f42c1; } /* Name.Namespace */
        .codehilite .nt { color: #22863a; } /* Name.Tag */
        .codehilite .nv { color: #e36209; } /* Name.Variable */
        .codehilite .ow { color: #d73a49; font-weight: bold; } /* Operator.Word */
        .codehilite .w { color: #bbbbbb; } /* Text.Whitespace */
        .codehilite .bp { color: #005cc5; } /* Name.Builtin.Pseudo */
        .codehilite .fm { color: #6f42c1; } /* Name.Function.Magic */
        .codehilite .py { color: #24292e; } /* Name */
        .codehilite .vc { color: #e36209; } /* Name.Variable.Class */
        .codehilite .vg { color: #e36209; } /* Name.Variable.Global */
        .codehilite .vi { color: #e36209; } /* Name.Variable.Instance */
        .codehilite .vm { color: #6f42c1; } /* Name.Variable.Magic */
    </style>
</head>
<body>
<div class="container">
<div class="header">
<h1>üöÄ AI Daily Digest</h1>
<p>May 09, 2025</p>
</div>
<div class="overview">
<h3>Today's Highlights:</h3>
<ul>
<li>Analysis of <strong>7 key AI developments</strong>.</li>
<li>Skill up tutorial on: <strong>LangGraph basics</strong>.</li>
</ul>
<p style="font-size: 0.9em; margin-top: 15px;">Jump to: 
<a href="#headlines">Headlines</a> | <a href="#tutorial">Tutorial</a> | <a href="#guides">Guides</a> | <a href="#spotlight">Google Spotlight</a> | <a href="#market">Market</a> | <a href="#actions">Actionable Ideas</a>
</p>
</div>
<div class="section">
<h2 id="headlines">üì∞ Top Headlines & Insights</h2>
<div class='item'>
<h3>Google launches ‚Äòimplicit caching‚Äô to make accessing its latest AI models cheaper</h3>
<p class='source-link'><a href="https://techcrunch.com/2025/05/08/google-launches-implicit-caching-to-make-accessing-its-latest-ai-models-cheaper/" target="_blank">https://techcrunch.com/2025/05/08/google-launches-implicit-caching-to-make-accessing-its-latest-ai-models-cheaper/</a></p>
<p><strong>Summary:</strong> Google has introduced &quot;implicit caching&quot; to lower the cost of accessing its advanced AI models. This new feature directly tackles cost efficiency concerns, making Google AI more accessible and budget-friendly. It&#x27;s particularly beneficial for businesses, especially AI startups, looking to reduce expenses while leveraging Google&#x27;s AI capabilities. The launch provides immediate cost-saving opportunities.</p>
</div>
<div class='item'>
<h3>OpenAI Expands Leadership with Fidji Simo</h3>
<p class='source-link'><a href="https://openai.com/index/leadership-expansion-with-fidji-simo" target="_blank">https://openai.com/index/leadership-expansion-with-fidji-simo</a></p>
<p><strong>Summary:</strong> OpenAI is expanding its leadership team with the addition of Fidji Simo, signaling a strategic shift. This move is likely to influence OpenAI&#x27;s direction and competitive position in the AI market. The announcement provides valuable insights for market analysis and understanding OpenAI&#x27;s future plans.</p>
</div>
<div class='item'>
<h3>OpenAI‚Äôs response to the Department of Energy on AI infrastructure</h3>
<p class='source-link'><a href="https://openai.com/global-affairs/response-to-department-of-energy" target="_blank">https://openai.com/global-affairs/response-to-department-of-energy</a></p>
<p><strong>Summary:</strong> OpenAI responded to the Department of Energy regarding its AI infrastructure, a key component of its long-term strategy. This response offers insights into OpenAI&#x27;s compute and resource planning, crucial for its future development. Understanding this infrastructure is vital for assessing the company&#x27;s capacity to scale and innovate within the AI space. The details are particularly relevant to Chief Technology Officers and those focused on AI resource management.</p>
</div>
<div class='item'>
<h3>How to build a better AI benchmark</h3>
<p class='source-link'><a href="https://www.technologyreview.com/2025/05/08/1116192/how-to-build-a-better-ai-benchmark/" target="_blank">https://www.technologyreview.com/2025/05/08/1116192/how-to-build-a-better-ai-benchmark/</a></p>
<p><strong>Summary:</strong> The article discusses the need for improved AI benchmarks, specifically highlighting SWE-Bench, a new benchmark focused on coding abilities.  SWE-Bench is designed to assess AI&#x27;s practical skills in real-world coding tasks. This shift towards evaluating practical application is considered a key step in advancing AI development, particularly for technologies like large language models. The article provides actionable insights into how to create more effective AI evaluations.</p>
</div>
<div class='item'>
<h3>Asking chatbots for short answers can increase hallucinations, study finds</h3>
<p class='source-link'><a href="https://techcrunch.com/2025/05/08/asking-chatbots-for-short-answers-can-increase-hallucinations-study-finds/" target="_blank">https://techcrunch.com/2025/05/08/asking-chatbots-for-short-answers-can-increase-hallucinations-study-finds/</a></p>
<p><strong>Summary:</strong> A new study indicates that requesting short answers from chatbots can increase the likelihood of them providing inaccurate or &quot;hallucinated&quot; information. Researchers found that concise responses make it harder for the models to cross-reference and verify the information they generate, leading to errors. This highlights the importance of thoughtful prompt engineering, suggesting users should consider longer, more detailed prompts to improve the reliability of chatbot outputs. The study&#x27;s implications could impact how we design and interact with language models.</p>
</div>
<div class='item'>
<h3>AI and the Future of Health with Joelle Barral</h3>
<p class='source-link'><a href="https://www.youtube.com/watch?v=8Q02UAfqwWU" target="_blank">https://www.youtube.com/watch?v=8Q02UAfqwWU</a></p>
<p><strong>Summary:</strong> This video explores the application of Artificial Intelligence in the healthcare sector, specifically highlighting Google DeepMind&#x27;s research. The discussion centers on AI&#x27;s potential for improving diagnostics using multi-modal models. The core focus is on the practical applications of AI, emphasizing Google&#x27;s efforts to transform healthcare through this technology.</p>
</div>
<div class='item'>
<h3>Introducing data residency in Asia</h3>
<p class='source-link'><a href="https://openai.com/index/introducing-data-residency-in-asia" target="_blank">https://openai.com/index/introducing-data-residency-in-asia</a></p>
<p><strong>Summary:</strong> OpenAI is expanding its data residency options to Asia, signaling a global strategy focused on compliance. This move allows users in Asia to store their data within the region. This is significant for businesses and CTOs operating internationally, as it facilitates easier adherence to data privacy regulations.</p>
</div>
</div>
<div class="section">
<h2 id="tutorial">üßë‚Äçüè´ Skill Up: Custom Tutorial - LangGraph basics</h2>
<p>This tutorial provides a fast-track introduction to LangGraph, focusing on building a simple graph-based agent flow. We'll create a graph with nodes representing different agent actions and edges dictating the flow of execution.</p>

<h3>Objective: Building a Simple Decision-Making Graph</h3>

<p>We'll create a graph where an agent can choose between searching the web or directly answering a question, followed by a final "generate response" node.</p>

<h3>Step 1: Install Dependencies</h3>

<p>First, install the necessary libraries:</p>

<div style="background: #272822; border: 1px solid #181a1f; padding: 12px 15px; border-radius: 3px; overflow-x: auto; font-family: Consolas, 'SFMono-Regular', 'Liberation Mono', Menlo, monospace; font-size: 14px; margin: 1em 0; line-height: 1.45; color: #abb2bf;"><pre style="margin: 0; line-height: 125%; background: transparent; border: none;"><code class="language-python"><div class="highlight" style="background: #272822"><span></span><span style="color: #F8F8F2">pip</span> <span style="color: #F8F8F2">install</span> <span style="color: #F8F8F2">langgraph</span> <span style="color: #F8F8F2">langchain</span> <span style="color: #F8F8F2">langchain_google_genai</span> <span style="color: #F8F8F2">beautifulsoup4</span> <span style="color: #F8F8F2">google</span><span style="color: #FF4689">-</span><span style="color: #F8F8F2">search</span><span style="color: #FF4689">-</span><span style="color: #F8F8F2">results</span>
</div>
</code></pre></div>

<h3>Step 2: Configure Environment Variables</h3>

<p>Set up your API keys for the LLM and any tools you'll be using (e.g., Google Gemini API, Serper API). For Google Gemini, you might not need an API key if using Google Cloud services directly.</p>

<div style="background: #272822; border: 1px solid #181a1f; padding: 12px 15px; border-radius: 3px; overflow-x: auto; font-family: Consolas, 'SFMono-Regular', 'Liberation Mono', Menlo, monospace; font-size: 14px; margin: 1em 0; line-height: 1.45; color: #abb2bf;"><pre style="margin: 0; line-height: 125%; background: transparent; border: none;"><code class="language-python"><div class="highlight" style="background: #272822"><span></span><span style="color: #FF4689">import</span><span style="color: #F8F8F2"> os</span>
<span style="color: #F8F8F2">os</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">environ[</span><span style="color: #E6DB74">&quot;GOOGLE_API_KEY&quot;</span><span style="color: #F8F8F2">]</span> <span style="color: #FF4689">=</span> <span style="color: #E6DB74">&quot;YOUR_GOOGLE_API_KEY&quot;</span>
<span style="color: #F8F8F2">os</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">environ[</span><span style="color: #E6DB74">&quot;GOOGLE_CSE_ID&quot;</span><span style="color: #F8F8F2">]</span> <span style="color: #FF4689">=</span> <span style="color: #E6DB74">&quot;YOUR_GOOGLE_CSE_ID&quot;</span> <span style="color: #959077"># optional for web search</span>
<span style="color: #F8F8F2">os</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">environ[</span><span style="color: #E6DB74">&quot;SERPAPI_API_KEY&quot;</span><span style="color: #F8F8F2">]</span> <span style="color: #FF4689">=</span> <span style="color: #E6DB74">&quot;YOUR_SERPAPI_API_KEY&quot;</span> <span style="color: #959077"># or use this if you prefer</span>
</div>
</code></pre></div>

<h3>Step 3: Define the Nodes</h3>

<p>Each node represents a distinct step in our agent's flow.  We'll create functions for searching the web, directly answering the question, and generating the final response.</p>

<div style="background: #272822; border: 1px solid #181a1f; padding: 12px 15px; border-radius: 3px; overflow-x: auto; font-family: Consolas, 'SFMono-Regular', 'Liberation Mono', Menlo, monospace; font-size: 14px; margin: 1em 0; line-height: 1.45; color: #abb2bf;"><pre style="margin: 0; line-height: 125%; background: transparent; border: none;"><code class="language-python"><div class="highlight" style="background: #272822"><span></span><span style="color: #FF4689">from</span><span style="color: #F8F8F2"> langchain_google_genai </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">ChatGoogleGenerativeAI</span>
<span style="color: #FF4689">from</span><span style="color: #F8F8F2"> langchain.tools </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">DuckDuckGoSearchRun</span>
<span style="color: #FF4689">from</span><span style="color: #F8F8F2"> langchain_core.prompts </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">ChatPromptTemplate,</span> <span style="color: #F8F8F2">MessagesPlaceholder</span>
<span style="color: #FF4689">from</span><span style="color: #F8F8F2"> langchain_core.runnables </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">chain</span>
<span style="color: #FF4689">from</span><span style="color: #F8F8F2"> langchain_core.messages </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">BaseMessage</span>

<span style="color: #959077"># Initialize LLM and tools</span>
<span style="color: #F8F8F2">llm</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">ChatGoogleGenerativeAI(model</span><span style="color: #FF4689">=</span><span style="color: #E6DB74">&quot;gemini-pro&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #F8F8F2">temperature</span><span style="color: #FF4689">=</span><span style="color: #AE81FF">0.7</span><span style="color: #F8F8F2">)</span>
<span style="color: #F8F8F2">search</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">DuckDuckGoSearchRun()</span>

<span style="color: #959077"># Node 1: Web Search</span>
<span style="color: #66D9EF">def</span><span style="color: #F8F8F2"> </span><span style="color: #A6E22E">search_web</span><span style="color: #F8F8F2">(question:</span> <span style="color: #F8F8F2">str):</span>
<span style="color: #F8F8F2">  </span><span style="color: #E6DB74">&quot;&quot;&quot;Searches the web for relevant information.&quot;&quot;&quot;</span>
  <span style="color: #66D9EF">return</span> <span style="color: #F8F8F2">search</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">run(question)</span>

<span style="color: #959077"># Node 2: Direct Answer (LLM&#39;s initial attempt)</span>
<span style="color: #66D9EF">def</span><span style="color: #F8F8F2"> </span><span style="color: #A6E22E">direct_answer</span><span style="color: #F8F8F2">(question:</span> <span style="color: #F8F8F2">str):</span>
<span style="color: #F8F8F2">  </span><span style="color: #E6DB74">&quot;&quot;&quot;Tries to answer the question directly using the LLM.&quot;&quot;&quot;</span>
  <span style="color: #F8F8F2">prompt</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">ChatPromptTemplate</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">from_messages([</span>
      <span style="color: #F8F8F2">(</span><span style="color: #E6DB74">&quot;system&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;Answer the user question concisely.&quot;</span><span style="color: #F8F8F2">),</span>
      <span style="color: #F8F8F2">(</span><span style="color: #E6DB74">&quot;user&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;{question}&quot;</span><span style="color: #F8F8F2">)</span>
  <span style="color: #F8F8F2">])</span>
  <span style="color: #66D9EF">return</span> <span style="color: #F8F8F2">prompt</span> <span style="color: #FF4689">|</span> <span style="color: #F8F8F2">llm</span>

<span style="color: #959077"># Node 3: Generate Final Response</span>
<span style="color: #66D9EF">def</span><span style="color: #F8F8F2"> </span><span style="color: #A6E22E">generate_response</span><span style="color: #F8F8F2">(input_dict:</span> <span style="color: #F8F8F2">dict):</span>
<span style="color: #F8F8F2">  </span><span style="color: #E6DB74">&quot;&quot;&quot;Generates the final response based on available information.&quot;&quot;&quot;</span>
  <span style="color: #F8F8F2">question</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">input_dict[</span><span style="color: #E6DB74">&quot;question&quot;</span><span style="color: #F8F8F2">]</span>
  <span style="color: #F8F8F2">context</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">input_dict</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">get(</span><span style="color: #E6DB74">&quot;web_search_result&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #66D9EF">None</span><span style="color: #F8F8F2">)</span>
  <span style="color: #F8F8F2">prompt_text</span> <span style="color: #FF4689">=</span> <span style="color: #E6DB74">f&quot;Question: {</span><span style="color: #F8F8F2">question</span><span style="color: #E6DB74">}</span><span style="color: #AE81FF">\n</span><span style="color: #E6DB74">&quot;</span>
  <span style="color: #66D9EF">if</span> <span style="color: #F8F8F2">context:</span>
    <span style="color: #F8F8F2">prompt_text</span> <span style="color: #FF4689">+=</span> <span style="color: #E6DB74">f&quot;Web Search Result: {</span><span style="color: #F8F8F2">context</span><span style="color: #E6DB74">}</span><span style="color: #AE81FF">\n</span><span style="color: #E6DB74">&quot;</span>
    <span style="color: #F8F8F2">prompt_text</span> <span style="color: #FF4689">+=</span> <span style="color: #E6DB74">&quot;Generate a comprehensive answer based on the search result.&quot;</span>
  <span style="color: #66D9EF">else</span><span style="color: #F8F8F2">:</span>
    <span style="color: #F8F8F2">prompt_text</span> <span style="color: #FF4689">+=</span> <span style="color: #E6DB74">&quot;No web search was performed. Answer the question based on your internal knowledge.&quot;</span>
  <span style="color: #F8F8F2">prompt</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">ChatPromptTemplate</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">from_messages([</span>
      <span style="color: #F8F8F2">(</span><span style="color: #E6DB74">&quot;system&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;You are a helpful assistant.&quot;</span><span style="color: #F8F8F2">),</span>
      <span style="color: #F8F8F2">(</span><span style="color: #E6DB74">&quot;user&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #F8F8F2">prompt_text)</span>
  <span style="color: #F8F8F2">])</span>
  <span style="color: #66D9EF">return</span> <span style="color: #F8F8F2">prompt</span> <span style="color: #FF4689">|</span> <span style="color: #F8F8F2">llm</span>
</div>
</code></pre></div>

<h3>Step 4: Define the Graph</h3>

<p>Now, we create the LangGraph and define the nodes and edges that connect them.  The key is using `StateGraph` and adding conditional edges.</p>

<div style="background: #272822; border: 1px solid #181a1f; padding: 12px 15px; border-radius: 3px; overflow-x: auto; font-family: Consolas, 'SFMono-Regular', 'Liberation Mono', Menlo, monospace; font-size: 14px; margin: 1em 0; line-height: 1.45; color: #abb2bf;"><pre style="margin: 0; line-height: 125%; background: transparent; border: none;"><code class="language-python"><div class="highlight" style="background: #272822"><span></span><span style="color: #FF4689">from</span><span style="color: #F8F8F2"> langgraph.graph </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">StateGraph,</span> <span style="color: #F8F8F2">END</span>

<span style="color: #959077"># Define the state (what&#39;s passed between nodes)</span>
<span style="color: #FF4689">from</span><span style="color: #F8F8F2"> typing </span><span style="color: #FF4689">import</span> <span style="color: #F8F8F2">TypedDict,</span> <span style="color: #F8F8F2">Dict,</span> <span style="color: #F8F8F2">Any</span>
<span style="color: #66D9EF">class</span><span style="color: #F8F8F2"> </span><span style="color: #A6E22E">GraphState</span><span style="color: #F8F8F2">(TypedDict):</span>
    <span style="color: #F8F8F2">question:</span> <span style="color: #F8F8F2">str</span>
    <span style="color: #F8F8F2">web_search_result:</span> <span style="color: #F8F8F2">str</span> <span style="color: #FF4689">|</span> <span style="color: #66D9EF">None</span>
    <span style="color: #F8F8F2">messages:</span> <span style="color: #F8F8F2">list[BaseMessage]</span> <span style="color: #959077"># Add messages for conversation history (optional)</span>

<span style="color: #959077"># Define the graph</span>
<span style="color: #F8F8F2">graph</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">StateGraph(GraphState)</span>

<span style="color: #959077"># Add nodes</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_node(</span><span style="color: #E6DB74">&quot;search_web&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #F8F8F2">search_web)</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_node(</span><span style="color: #E6DB74">&quot;direct_answer&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #F8F8F2">direct_answer)</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_node(</span><span style="color: #E6DB74">&quot;generate_response&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #F8F8F2">generate_response)</span>

<span style="color: #959077"># Define edges and conditional logic</span>
<span style="color: #66D9EF">def</span><span style="color: #F8F8F2"> </span><span style="color: #A6E22E">decide_to_search</span><span style="color: #F8F8F2">(state:</span> <span style="color: #F8F8F2">GraphState):</span>
<span style="color: #F8F8F2">    </span><span style="color: #E6DB74">&quot;&quot;&quot;Determine whether to search the web based on the question.  You can use an LLM here for more sophisticated logic.&quot;&quot;&quot;</span>
    <span style="color: #F8F8F2">question</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">state[</span><span style="color: #E6DB74">&quot;question&quot;</span><span style="color: #F8F8F2">]</span>
    <span style="color: #959077"># Simple heuristic: search if the question contains &quot;what&quot;, &quot;who&quot;, &quot;when&quot;, &quot;where&quot;, &quot;how&quot;</span>
    <span style="color: #66D9EF">if</span> <span style="color: #F8F8F2">any(keyword</span> <span style="color: #FF4689">in</span> <span style="color: #F8F8F2">question</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">lower()</span> <span style="color: #66D9EF">for</span> <span style="color: #F8F8F2">keyword</span> <span style="color: #FF4689">in</span> <span style="color: #F8F8F2">[</span><span style="color: #E6DB74">&quot;what&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;who&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;when&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;where&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;how&quot;</span><span style="color: #F8F8F2">]):</span>
        <span style="color: #66D9EF">return</span> <span style="color: #E6DB74">&quot;search_web&quot;</span>  <span style="color: #959077"># Key must match the node name</span>
    <span style="color: #66D9EF">else</span><span style="color: #F8F8F2">:</span>
        <span style="color: #66D9EF">return</span> <span style="color: #E6DB74">&quot;direct_answer&quot;</span>

<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_node(</span><span style="color: #E6DB74">&quot;should_search&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #F8F8F2">decide_to_search)</span> <span style="color: #959077"># The conditional node must be added as a node</span>

<span style="color: #959077"># Build the graph</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_edge(</span><span style="color: #E6DB74">&quot;search_web&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;generate_response&quot;</span><span style="color: #F8F8F2">)</span> <span style="color: #959077"># After search, go to generating a response</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_edge(</span><span style="color: #E6DB74">&quot;direct_answer&quot;</span><span style="color: #F8F8F2">,</span> <span style="color: #E6DB74">&quot;generate_response&quot;</span><span style="color: #F8F8F2">)</span> <span style="color: #959077"># After direct answer, go to generating a response</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">add_conditional_edges(</span>
    <span style="color: #F8F8F2">start_node</span><span style="color: #FF4689">=</span><span style="color: #E6DB74">&quot;should_search&quot;</span><span style="color: #F8F8F2">,</span>
    <span style="color: #F8F8F2">condition_func</span><span style="color: #FF4689">=</span><span style="color: #F8F8F2">decide_to_search,</span>
    <span style="color: #F8F8F2">conditional_edge_mapping</span><span style="color: #FF4689">=</span><span style="color: #F8F8F2">{</span>
        <span style="color: #E6DB74">&quot;search_web&quot;</span><span style="color: #F8F8F2">:</span> <span style="color: #E6DB74">&quot;search_web&quot;</span><span style="color: #F8F8F2">,</span>
        <span style="color: #E6DB74">&quot;direct_answer&quot;</span><span style="color: #F8F8F2">:</span> <span style="color: #E6DB74">&quot;direct_answer&quot;</span><span style="color: #F8F8F2">,</span>
    <span style="color: #F8F8F2">}</span>
<span style="color: #F8F8F2">)</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">set_entry_point(</span><span style="color: #E6DB74">&quot;should_search&quot;</span><span style="color: #F8F8F2">)</span> <span style="color: #959077"># Where the graph starts</span>
<span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">set_finish_point(</span><span style="color: #E6DB74">&quot;generate_response&quot;</span><span style="color: #F8F8F2">)</span> <span style="color: #959077">#Where the graph exits.</span>
<span style="color: #959077"># Compile the graph</span>
<span style="color: #F8F8F2">app</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">graph</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">compile()</span>
</div>
</code></pre></div>

<h3>Step 5: Run the Graph</h3>

<p>Now, execute the graph with a sample question.</p>

<div style="background: #272822; border: 1px solid #181a1f; padding: 12px 15px; border-radius: 3px; overflow-x: auto; font-family: Consolas, 'SFMono-Regular', 'Liberation Mono', Menlo, monospace; font-size: 14px; margin: 1em 0; line-height: 1.45; color: #abb2bf;"><pre style="margin: 0; line-height: 125%; background: transparent; border: none;"><code class="language-python"><div class="highlight" style="background: #272822"><span></span><span style="color: #959077"># Example usage</span>
<span style="color: #F8F8F2">inputs</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">{</span><span style="color: #E6DB74">&quot;question&quot;</span><span style="color: #F8F8F2">:</span> <span style="color: #E6DB74">&quot;What is the capital of France?&quot;</span><span style="color: #F8F8F2">}</span>
<span style="color: #F8F8F2">results</span> <span style="color: #FF4689">=</span> <span style="color: #F8F8F2">app</span><span style="color: #FF4689">.</span><span style="color: #F8F8F2">invoke(inputs)</span>

<span style="color: #F8F8F2">print(results)</span> <span style="color: #959077"># {&quot;question&quot;: ..., &quot;web_search_result&quot;: ..., &quot;messages&quot;: ..., &#39;generate_response&#39;: ...}</span>
<span style="color: #F8F8F2">print(results[</span><span style="color: #E6DB74">&#39;generate_response&#39;</span><span style="color: #F8F8F2">])</span>
</div>
</code></pre></div>

<h3>Key Considerations for Production</h3>

<ul>
  <li><strong>Error Handling:</strong> Implement robust error handling within each node and in the graph execution (e.g., using `try...except` blocks). Log errors comprehensively.</li>
  <li><strong>API Rate Limits:</strong> Be mindful of API rate limits for LLMs and search tools. Implement retry logic with exponential backoff.</li>
  <li><strong>Observability:</strong>  Use LangSmith or other tracing tools to monitor graph execution, identify bottlenecks, and debug issues.  Leverage structured logging for each node's input and output.</li>
  <li><strong>State Management:</strong>  For conversational agents, carefully manage the state passed between nodes, including conversation history. Consider using a database or key-value store for persistent state.</li>
  <li><strong>Authentication:</strong> When using Google Cloud services, leverage service accounts for secure authentication instead of API keys when possible.</li>
</ul>

<h3>LangGraph and Google Ecosystem</h3>

<p>LangGraph can seamlessly integrate with several Google AI services:</p>

<ul>
  <li><strong>Vertex AI:</strong> Deploy your LangGraph application as a Vertex AI endpoint for scalable inference.</li>
  <li><strong>Google Cloud Storage:</strong> Store and retrieve data (e.g., prompts, knowledge base documents) using Google Cloud Storage.</li>
  <li><strong>Label Studio:</strong>  Use Label Studio to create training datasets for fine-tuning LLMs used within your LangGraph nodes.  This helps improve the accuracy and relevance of responses.</li>
</ul>

<p>This tutorial provides a solid foundation for building more complex LangGraph-based agents. Experiment with different nodes, edge conditions, and integration with other tools to create powerful and customized AI applications.</p>

</div>
<div class="section">
<h2 id="guides">‚öôÔ∏è Guides & Tutorials From Your Feeds</h2>
<p><em>No relevant tutorial items found in feeds today.</em></p>
</div>
<div class="section">
<h2 id="spotlight"><img src="https://www.google.com/favicon.ico" class="google-icon" alt="G"> Google Spotlight</h2>
<ul>
<li><a href="https://techcrunch.com/2025/05/08/google-launches-implicit-caching-to-make-accessing-its-latest-ai-models-cheaper/" target="_blank">üì∞ Google launches ‚Äòimplicit caching‚Äô to make accessing its latest AI models cheaper</a></li>
<li><a href="https://www.youtube.com/watch?v=8Q02UAfqwWU" target="_blank">üì∞ AI and the Future of Health with Joelle Barral</a></li>
</ul>
</div>
<div class="section market-pulse-list">
<h2 id="market">üìà Market Pulse</h2>
<p><em>Key market shifts and competitive observations today include:</em></p>
<p><em>No specific market analysis points identified in today's items.</em></p>
</div>
<div class="section actionable-ideas-list">
<h2 id="actions">‚ö° Actionable Ideas & Questions</h2>
<p><em>No specific project applications identified in today's items based on provided context.</em></p>
</div>
<div class="footer">
Generated by AI Digest Agent.
</div>
</div>
</body>
</html>